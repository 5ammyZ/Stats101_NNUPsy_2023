---
format: 
  revealjs:
    slide-number: true
    logo: images/image-393370223.png
    scrollable: true 
    theme: theme.scss
editor: visual
fontsize: 24pt
---

</br></br>

<h1 style="text-align: center">

5 回归分析

</h1>

<h2 style="text-align: center">

</h2>

</br></br>

<h3 style="text-align: center">

Hu Chuan-Peng

</h3>

<h3 style="text-align: center">

2023-10-10

</h3>

</br></br>

# 本次课内容

-   ANOVA的三种计算方式

-   线性回归的三种解读

-   残差

-   模型性能的评估

# 复习

## 

-   为什么要使用ANOVA?

-   ANOVA的原理

-   不同的ANOVA的类型

    -   单因素ANOVA -\> 单因素完全随机设计

    -   两因素ANOVA -\> 两因素完全随机设计

    -   单因素重复测量ANOVA -\> 单因素被试内设计

    -   两因素重复测量ANOVA -\> 两因素被试内设计

    -   混合设计ANOVA -\> 混合设计

-   工作流程

## 两因素重复测量设计被试安排

![](images/1696419717392.jpg){fig-align="center"}

参考来源：舒华《心理与教育研究中的多因素实验设计》

## 两因素重复测量设计变异与自由度分解

![](images/1696419859457.jpg){fig-align="center"}

## 两因素混合设计被试安排

![](images/1696419963213.png){fig-align="center"}

参考来源：舒华《心理与教育研究中的多因素实验设计》

## 两因素混合设计变异与自由度分解

![](images/1696420008459.jpg){fig-align="center"}

## 工作流程

1.  提出假设。

2.  根据研究假设$H_{0}$和$H_{1}$，选择相应的统计模型。

3.  确定显著性水平$\alpha$，$\alpha$确定后，否定域也随之被确定了。

4.  基于$H_{0}$所设定的统计模型，计算检验统计量的值。

5.  做出决策。结果呈现，报告撰写。



# 线性回归

## 问题引入

瑞文推理测试是一种常用的心理测量工具，旨在评估个体的推理能力和问题解决能力。测试中包含各种类型的问题，包括数学、语言、空间和逻辑等方面的问题，需要受试者通过分析、推理和解决问题来得出正确答案。研究者想要探究问题解决能力与家庭收入之间是否存在联系



```{r echo=TRUE}
# 读取数据并选取感兴趣的变量
df <- read.csv('data/example5.csv')%>%
  select(HouseholdIncome,ravens.score)
# 将变量进行归一化获得两列变量的标准分数
df_norm <- as.data.frame(scale(df))
df_norm
```

## 

如何表示变量间的关系

## 相关分析

```{r echo=TRUE}
Corr(df_norm)
```




## 皮尔逊相关系数

$$r = \frac{\sum(x-\bar{x})(y-\bar{y})}{ns_{x}s_{y}}=\frac{\sum z_{x}z_{y}}{n}$$ $$\downarrow$$ $$\hat{z_{y}}=rz_{x}$$ 

##


```{r echo=TRUE}
ggplot(data = df_norm, mapping = aes(x=ravens.score,y=HouseholdIncome))+
  geom_point()+
  theme_apa()
```

$$\hat{Z_{y}} = rZ_{x}$$

根据相关系数用X的标准分数来预测Y的标准分数吗？



##


$$\hat{Z_{y}} = rZ_{x}$$

```{r echo=TRUE}
ggplot(data = df_norm, mapping = aes(x=ravens.score,y=HouseholdIncome))+
  geom_point()+# 散点图
  geom_hline(yintercept = 0, color = "red") + # y=0直线
  geom_smooth(method = "lm", se = FALSE, color = "lightblue")+ # 拟合直线
  theme_apa()+ # apa格式主题
  annotate("text", x = -2, y = 5, label = "r = 0.12", size = 5) # 添加文字
```







##

除了使用相关系数，我们该如何表示原始分数之间的关系？

## 

$$\hat{z_{y}}=rz_{x}$$

$$\downarrow$$ $$\frac{\hat{y}-\mu_{y}}{\sigma_{y}}=r \frac{x-\mu_{x}}{\sigma_{x}}$$

$$\downarrow$$

$$\hat{y}=\frac{\sigma_{y}}{\sigma_{x}}r(x-\mu_{x})+\mu_{y}$$

$$\downarrow$$

$$b_{yx} = \frac{\sigma_{y}}{\sigma_{x}}r, a_{yx}=\mu_{y}-b_{yx}\mu_{x}$$

$$\hat{y}=b_{yx}x+a_{yx}$$



##


```{r echo=TRUE}
model <- lm(HouseholdIncome~ravens.score,data=df_norm) # 线性回归
summary(model) # 模型拟合结果
```



##

$$\hat{Z_{y}} = b_{yx}Z_{x}+a_{yx}$$

```{r echo=TRUE}
ggplot(data = df_norm, mapping = aes(x=ravens.score,y=HouseholdIncome))+
  geom_point()+# 散点图
  geom_hline(yintercept = 0, color = "red") + # y=0直线
  geom_smooth(method = "lm", se = FALSE, color = "lightblue")+ # 拟合直线
  theme_apa()+ # apa格式主题
  annotate("text", x = -2, y = 5, label = "直线斜率：byx = 0.12", size = 5) # 添加文字
```

## 用标准分数进行回归分析

```{r echo=TRUE}
res <- lm(HouseholdIncome~ravens.score,data=df) # 线性回归
summary(res) # 模型拟合结果
```


## 用原始分数进行回归分析

$$\hat{y} = b_{yx}x+a_{yx}$$


```{r echo=TRUE}
ggplot(data = df, mapping = aes(x=ravens.score,y=HouseholdIncome))+
  geom_point()+# 散点图
  geom_hline(yintercept = mean(df$HouseholdIncome), color = "red") + # y=householdIncome均值直线
  geom_smooth(method = "lm", se = FALSE, color = "lightblue")+ # 拟合直线
  theme_apa()+ # apa格式主题
  annotate("text", x = 3, y = 200000, label = "直线斜率：byx = 896.9", size = 5) # 添加文字
```





# 线性回归的三种解读

## 三种视角

$$观测项=结构项+随机项$$ - 观测项：因变量的实际取值

-   结构项：因变量与自变量间的结构关系，"预测值"

-   随机项：观测项中未被结构项解释的的部分，包含被忽略的结构因素，测量误差和随机干扰

## 描述性

$$观测项=概括项+残差项$$ - 不关注模型是否"真实"，只关注是否符合已被观察到的事实。

-   "奥卡姆剃刀定律"：如果许多模型对所观察的事实解释程度得当，除非有其他证据支持某一模型，否则我们倾向于选择 最简单的模型

## 预测性

$$观测项 = 预测项 + 误差项$$

-   已知一组自变量和因变量之间的关系，用新的数据给出有用的预测回答，通过经验规律做预测，对因果机制不在乎或不感兴趣。

## 因果性

$$观测项 = 机制项 + 干扰项$$

-   确立模型以发现数据产生的机制，发现"真实"的因果模型，但当前更多学者认为，这种模型并不存在，好的模型只是更接近真实，或更有意义

# 残差

## 残差

![](images/1696426750516.jpg){fig-align="center"}

实际观测值与估计值（拟合值）之间的差异。这些误差（error），或称残差（residual），衡量每个观测值与该观测值的预测值之间的距离。



## 总变异


$$\frac{\sum (y-\bar{y})^2}{N}$$

这部分变异代表每个数据点的总变异


```{r echo=TRUE}
ggplot(data = df, mapping = aes(x=ravens.score,y=HouseholdIncome))+
  geom_point()+# 散点图
  geom_hline(yintercept = mean(df$HouseholdIncome), color = "red") + # y=householdIncome均值直线
  geom_line(aes(x=ravens.score,y=predict(lm(HouseholdIncome ~ ravens.score, data = df))),color='lightblue')+
  theme_apa()+ # apa格式主题
  annotate("text", x = 3, y = 200000, label = "直线斜率：byx = 896.9", size = 5)+ # 添加文字
  xlim(0,5)+
  ylim(0,70000)+
  geom_segment(aes(x = ravens.score, 
                   y = HouseholdIncome, 
                   xend = ravens.score, 
                   yend = mean(HouseholdIncome)), 
               color = "pink", 
               alpha = 1)
```



## 模型可解释的变异


$$\frac{\sum (\hat{y}-\bar{y})^2}{N}$$

这部分变异代表每个数据点可以被回归模型解释的变异



```{r echo=TRUE}
ggplot(data = df, mapping = aes(x=ravens.score,y=HouseholdIncome))+
  geom_point()+# 散点图
  geom_hline(yintercept = mean(df$HouseholdIncome), color = "red") + # y=householdIncome均值直线
  geom_line(aes(x=ravens.score,y=predict(lm(HouseholdIncome ~ ravens.score, data = df))),color='lightblue')+
  theme_apa()+ # apa格式主题
  annotate("text", x = 3, y = 200000, label = "直线斜率：byx = 896.9", size = 5)+ # 添加文字
  xlim(0,5)+
  ylim(0,70000)+
  geom_segment(aes(x = ravens.score, 
                   y = predict(lm(HouseholdIncome ~ ravens.score, data = df)), 
                   xend = ravens.score, 
                   yend = mean(HouseholdIncome)), 
               color = "pink", 
               alpha = 1)
```




##

$$\frac{\sum (y-\hat{y})^2}{N}$$

这部分变异代表每个数据点无法被回归模型解释的变异

```{r echo=TRUE}
ggplot(data = df, mapping = aes(x=ravens.score,y=HouseholdIncome))+
  geom_point()+# 散点图
  geom_hline(yintercept = mean(df$HouseholdIncome), color = "red") + # y=householdIncome均值直线
  #geom_smooth(method = "lm", se = FALSE, color = "lightblue")+ # 拟合直线
  geom_line(aes(x=ravens.score,y=predict(lm(HouseholdIncome ~ ravens.score, data = df))),color='lightblue')+
  theme_apa()+ # apa格式主题
  annotate("text", x = 3, y = 200000, label = "直线斜率：byx = 896.9", size = 5)+ # 添加文字
  xlim(0,5)+
  ylim(0,70000)+
  geom_segment(aes(x = ravens.score, y = HouseholdIncome, xend = ravens.score, yend = predict(lm(HouseholdIncome ~ ravens.score, data = df))), color = "pink", alpha = 1)
```




## 回归表达形式

简单线性回归(Simple Linear Regression)

$$y = a + bX + \epsilon$$

-   y -- 因变量，Dependent variable

-   x -- 自变量，Independent (explanatory) variable

-   a -- 截距，Intercept

-   b -- 斜率，Slope

-   $\epsilon$ -- 残差，Residual (error)

## 

简单线性回归(Simple Linear Regression)

$$y = a + bX + \epsilon$$ $$数据=模型+误差$$ \##

简单线性回归(Simple Linear Regression)

$$y = a + bX + \epsilon$$ $$数据=模型+误差$$

![](images/1696427713547(1).jpg){fig-align="center"}

## 回归模型的基本假定

1.模型设定假定

-   假定y的条件均值是自变量X的线性函数


2.正交假定

-   误差项$\epsilon$与x不相关$cov(x,\epsilon)= 0$

-   误差项$\epsilon$的期望值为0，即$E(\epsilon) = 0$


##


```{r echo=TRUE}
model <- lm(HouseholdIncome~ravens.score,data=df) # 线性回归
residuals <- resid(model)# 提取残差

print(paste('残差的平均值为',format(mean(residuals),digits =3),'残差与自变量的皮尔逊相关值为:',
correlation::cor_to_p(cor(residuals,df$ravens.score),n=522)$statistic,'p值为:',correlation::cor_to_p(cor(residuals,df$ravens.score),n=522)$p))
```



##

3.独立同分布假定

-   误差项$\epsilon$相互独立，并遵循同一分布。

    -   任何两个误差项的协方差为0。

    -   所有误差的方差相同。



##


```{r echo=TRUE}
hist(residuals)
```




4.正态分布假定

-   虽然假定$\epsilon$同分布，但仍然无法确定$\epsilon$的实际分布。对于大样本，可以采用中心极限定理进行统计推断。对于小样本，需要假定误差项$\epsilon$服从均值为0，方差为$\sigma^2$的正态分布。


```{r echo=TRUE}
qqnorm(residuals)
qqline(residuals)
shapiro.test(residuals)
```


# 模型性能的评估

## 

$$观测项=结构项+随机项$$

-   因果性：观测项 = 机制项 + 干扰项

-   预测性：观测项 = 预测项 + 误差项

-   描述性：观测项 = 概括项 + 残差项

## 模型性能

$$观测项=结构项+随机项， 模型性能=\frac{结构项}{观测项}$$

-   因果性：观测项 = 机制项 + 干扰项，$模型性能=\frac{机制项}{观测项}$

-   预测性：观测项 = 预测项 + 误差项，$模型性能=\frac{预测项}{观测项}$

-   描述性：观测项 = 概括项 + 残差项，$模型性能=\frac{概括项}{观测项}$

## 均方根误差

均方根误差(Mean-Squared Error, MSE)量化了预测值与真实值的接近程度，因此我们将用它来量化回归线与一组点的接近程度。每个数据点和回归线之间的距离平方，给离回归线较远的点更多的权重。

$$MSE=\frac{1}{n}\sum(y_{i}-\hat{y_{i}})^2$$

## R方

R方(R-Squared)，拟合优度、判定系数，它概括了一个模型对一组数据的拟合程度。线性回归最常用的拟合度指标是r-squared，这个指标表示我们的自变量所解释的因变量的方差的百分比，相对于模型的基线方差（平均值的方差），解释方差的百分比。

$$R^2 = 1 - \frac{\sum(y_{i}-\hat{y_{i}})^2}{\sum(y_{i}-\bar{y_{i}})^2}$$

## 

![](images/1696429339624.jpg){fig-align="center"}

## 

![](images/1696429403063.jpg){fig-align="center"}

## 三种模型评估指标的比较

$$\eta^2=\frac{SS_{b}}{SS_{b}+SS_{w}}$$

$$R^2=\frac{SS_{R}}{SS_{T}}=\frac{\sum(y_{i}-\hat{y_{i}})^2}{\sum(y_{i}-\bar{y_{i}})^2}$$

$$F=\frac{MS_{b}}{MS_{w}}=\frac{\frac{SS_{b}}{df_{b}}}{\frac{SS_{w}}{df_{w}}}$$

## 

![](images/1696429769384.jpg){fig-align="center"}

## 应用

1.  线性回归在心理学中的应用：描述性视角

![](images/1696429947888.jpg){fig-align="center"}

认知冲突和奖励信号都被提议加强任务相关的关联。 研究者提出假设：奖励能调节对冲突的适应性。结果表明，冲突适应效应（奖励后冲突调节的一致性效应减去无奖励后）的差异与BAS-奖励-响应性子量表相关 （**r** = .553，**p** \< .05，Spearman's $\rho$ = .460，**p** = .090） (Senne Braem, 2012)

## 

1.  线性回归在心理学中的应用：描述性视角

![](images/1696430042207-01.jpg){fig-align="center"}

特质焦虑对急性心理性应激反应的预测，结果显示，特质焦虑与心率急性应激反应负相关(**r** = -0.32, **p** \< 0.05)。 (彭惠妮等, 2022)

## 

2.线性回归在机器学习中的应用：预测性视角

![](images/1696430458943.jpg){fig-align="center"}

通过回归模型来通过自变量预测因变量(Pang Wei Koh, 2017)

## 

3.线性回归在经济学中的应用：因果性视角

![](images/1696430579912.jpg){fig-align="center"}

(方观富, 2020)

# 总结

-   ANOVA的三种计算方式

-   线性回归的三种解读

-   残差

-   模型性能的评估
